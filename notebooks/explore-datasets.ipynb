{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db975d2e5bf520c",
   "metadata": {},
   "source": [
    "Using the example from the [SS tutorial](https://www.semanticscholar.org/product/api/tutorial#retrieving-releases-datasets-and-download-links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T07:24:49.090904952Z",
     "start_time": "2024-06-27T07:24:49.023056662Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4220f1f97d91e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T07:24:51.734207428Z",
     "start_time": "2024-06-27T07:24:51.727369943Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define base URL for datasets API\n",
    "base_url = \"https://api.semanticscholar.org/datasets/v1/release/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff197c4486f624fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T07:24:56.597800960Z",
     "start_time": "2024-06-27T07:24:56.570106862Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(verbose=True)\n",
    "api_key = os.getenv('S2_API_KEY')\n",
    "headers = {\"x-api-key\": api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4dab2447f533ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T07:24:59.485887875Z",
     "start_time": "2024-06-27T07:24:59.002912174Z"
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(base_url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df69ad7cabf872df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T07:25:00.334064052Z",
     "start_time": "2024-06-27T07:25:00.320184063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['2022-05-10',\n '2022-05-17',\n '2022-05-24',\n '2022-05-31',\n '2022-06-07',\n '2022-06-14',\n '2022-06-21',\n '2022-06-28',\n '2022-07-05',\n '2022-07-19',\n '2022-07-28',\n '2022-08-02',\n '2022-08-09',\n '2022-08-16',\n '2022-08-23',\n '2022-08-30',\n '2022-09-06',\n '2022-09-13',\n '2022-09-28',\n '2022-10-05',\n '2022-10-28',\n '2022-11-02',\n '2022-11-11',\n '2022-11-15',\n '2022-11-22',\n '2022-12-02',\n '2022-12-06',\n '2022-12-13',\n '2022-12-20',\n '2022-12-27',\n '2023-01-03',\n '2023-01-10',\n '2023-01-17',\n '2023-01-24',\n '2023-01-31',\n '2023-02-07',\n '2023-02-14',\n '2023-02-21',\n '2023-02-28',\n '2023-03-07',\n '2023-03-14',\n '2023-03-21',\n '2023-03-28',\n '2023-04-06',\n '2023-04-11',\n '2023-04-18',\n '2023-05-09',\n '2023-05-16',\n '2023-05-23',\n '2023-05-30',\n '2023-06-06',\n '2023-06-13',\n '2023-06-20',\n '2023-07-04',\n '2023-07-11',\n '2023-07-25',\n '2023-08-01',\n '2023-08-08',\n '2023-08-15',\n '2023-08-29',\n '2023-09-05',\n '2023-09-12',\n '2023-09-19',\n '2023-09-26',\n '2023-10-10',\n '2023-10-19',\n '2023-10-24',\n '2023-10-31',\n '2023-11-07',\n '2023-11-14',\n '2023-11-21',\n '2023-11-28',\n '2023-12-05',\n '2023-12-12',\n '2023-12-27',\n '2024-01-02',\n '2024-01-24',\n '2024-01-30',\n '2024-02-06',\n '2024-02-20',\n '2024-02-27',\n '2024-03-05',\n '2024-03-12',\n '2024-03-19',\n '2024-03-26',\n '2024-04-02',\n '2024-04-09',\n '2024-04-16',\n '2024-04-23',\n '2024-04-30',\n '2024-05-07',\n '2024-05-14',\n '2024-05-21',\n '2024-05-28',\n '2024-06-04',\n '2024-06-11',\n '2024-06-18']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d10fbd808397d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:09.314253224Z",
     "start_time": "2024-06-21T05:19:09.193965152Z"
    }
   },
   "outputs": [],
   "source": [
    "release_id = data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6371c44a677bc006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:09.410790552Z",
     "start_time": "2024-06-21T05:19:09.315335091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2024-06-11'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34f161b6c545fae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:10.201740730Z",
     "start_time": "2024-06-21T05:19:09.405238613Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets_response = requests.get(base_url + release_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45a7f7da01de0574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:10.210789639Z",
     "start_time": "2024-06-21T05:19:10.202188340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea97a852cbdbdb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:10.284767789Z",
     "start_time": "2024-06-21T05:19:10.206855921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'name': 'abstracts',\n  'description': 'Paper abstract text, where available.\\n100M records in 30 1.8GB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"abstracts\" dataset provides abstract text for selected papers.\\n\\nSCHEMA\\n - openAccessInfo\\n   - externalIds: IDs of this paper in different catalogs\\n   - license/url/status: open-access information provided by Unpaywall, linked by DOI or PubMed Central ID\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}'},\n {'name': 'authors',\n  'description': 'The core attributes of an author (name, affiliation, paper count, etc.). Authors have an \"authorId\" field, which can be joined to the \"authorId\" field of the members of a paper\\'s \"authors\" field.\\n75M records in 30 100MB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"authors\" dataset provides summary information about authors.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Author-Data\\n\\nThis dataset does not contain information about an author\\'s papers.\\nInstead, join with authors.authorId from the \"papers\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}'},\n {'name': 'citations',\n  'description': 'Instances where the bibliography of one paper (the \"citingPaper\") mentions another paper (the \"citedPaper\"), where both papers are identified by the \"paperId\" field. Citations have attributes of their own, (influential classification, intent classification, and citation context).\\n2.4B records in 30 8.5GB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"citations\" dataset provides details about one paper\\'s citation of another paper.\\n\\nSCHEMA\\n - isinfluential: true/false if the citation is considered influential. https://www.semanticscholar.org/faq#influential-citations\\n - contexts: Text surrounding the citation in the source paper\\'s body.\\n - intents: Classification of the intent behind the citations. https://www.semanticscholar.org/faq#citation-intent\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}\\n\\n@inproceedings{cohan-etal-2019-structural,\\n    title = \"Structural Scaffolds for Citation Intent Classification in Scientific Publications\",\\n    author = \"Cohan, Arman  and\\n      Ammar, Waleed  and\\n      van Zuylen, Madeleine  and\\n      Cady, Field\",\\n    booktitle = \"NAACL\",\\n    year = \"2019\",\\n    url = \"https://aclanthology.org/N19-1361\",\\n    doi = \"10.18653/v1/N19-1361\"\\n}'},\n {'name': 'embeddings-specter_v1',\n  'description': 'A dense vector embedding representing the contents of the paper.\\n120M records in 30 28GB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"embeddings-specter_v1\" dataset provides embeddings representing a paper\\'s contents in vector form.\\n\\nThe model is based on the SPECTER model available at https://github.com/allenai/specter. However, the embeddings\\nincluded in this dataset are not compatible with the embeddings produced by the pretrained model from that repo.\\n\\nLICENSE\\nThis software is released under the Apache 2.0 license. (https://www.apache.org/licenses/LICENSE-2.0)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@inproceedings{specter2020cohan,\\n  title={{SPECTER: Document-level Representation Learning using Citation-informed Transformers}},\\n  author={Arman Cohan and Sergey Feldman and Iz Beltagy and Doug Downey and Daniel S. Weld},\\n  booktitle={ACL},\\n  year={2020}\\n}\\n\\n'},\n {'name': 'embeddings-specter_v2',\n  'description': 'A dense vector embedding representing the contents of the paper, generated with SPECTER2\\n120M records in 30 28GB files.\\n',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"embeddings-specter_v2\" dataset provides embeddings representing a paper\\'s contents in vector form.\\n\\nThe model is based on the SPECTER 2.0 model available at:\\nhttps://github.com/allenai/SPECTER2_0\\n\\nThese embeddings are compatible with embeddings produced by the pretrained\\nmodel, available from https://huggingface.co/allenai/specter2\\n\\nLICENSE\\nThis software is released under the Apache 2.0 license. (https://www.apache.org/licenses/LICENSE-2.0)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@article{Singh2022SciRepEvalAM,\\n  title={SciRepEval: A Multi-Format Benchmark for Scientific Document Representations},\\n  author={Amanpreet Singh and Mike D\\'Arcy and Arman Cohan and Doug Downey and Sergey Feldman},\\n  journal={ArXiv},\\n  year={2022},\\n  volume={abs/2211.13308},\\n  url={https://api.semanticscholar.org/CorpusID:254018137}\\n}\\n'},\n {'name': 'paper-ids',\n  'description': 'Mapping from sha-based ID to paper corpus ID.\\n450M records in 30 500MB files',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"paper-ids\" dataset provides mapping between different IDs representing a paper\\n\\nThe primary key of a paper in the S2AG datasets is the corpusId field. However, the public API and web site also accept a sha-based ID, which is also used in some research datasets. This dataset provides a mapping between the different IDs.\\n\\nSCHEMA\\ncorpusId - The paper\\'s primary key\\nsha - A sha-based ID that can be used to access the paper via our API or web site\\nprimary - There should be only one primary sha for each corpusId. Accessing papers using a non-primary sha will redirect to the primary sha.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}\\n\\n\\n'},\n {'name': 'papers',\n  'description': 'The core attributes of a paper (title, authors, date, etc.).\\n200M records in 30 1.5GB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"papers\" dataset provides core metadata about papers.\\n\\nSCHEMA\\nSee https://api.semanticscholar.org/api-docs/graph#tag/Paper-Data\\n\\nThis dataset does not contain information about a paper\\'s references or citations.\\nInstead, join with citingPaperId/citedPaperId from the \"citations\" dataset.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}\\n\\n\\n'},\n {'name': 'publication-venues',\n  'description': 'Details about the venues in which papers are published.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"publication-venues\" dataset contains meta-data for a research paper\\'s publication\\njournal or venue. The data sources of the venue data comes from The Fatcat Archive, documented\\nhere: https://archive.org/details/fatcat_snapshots_and_exports?sort=-publicdate, and the now deprecated Microsoft\\nAcademic Graph (MAG).\\n\\nSCHEMA\\n - id: The id of the venue data. The value also corresponds to the \"venueId\" field in the papers dataset.\\n - issn: The issn of the publication venue\\n - alternate_issns: The alternative issns for the publication venue\\n - name: The name of the venue\\n - alternate_names: The alternative names for the publication venue\\n - url:  The publication venue\\'s url\\n - alternate_urls: The alternative urls of the publication venue\\n - type: The type (journal / conference) of the publication venue\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@misc{https://doi.org/10.48550/arxiv.2301.10140,\\n  title = {The Semantic Scholar Open Data Platform},\\n  author = {Kinney, Rodney and Anastasiades, Chloe and Authur, Russell and Beltagy, Iz and Bragg, Jonathan and Buraczynski, Alexandra and Cachola, Isabel and Candra, Stefan and Chandrasekhar, Yoganand and Cohan, Arman and Crawford, Miles and Downey, Doug and Dunkelberger, Jason and Etzioni, Oren and Evans, Rob and Feldman, Sergey and Gorney, Joseph and Graham, David and Hu, Fangzhou and Huff, Regan and King, Daniel and Kohlmeier, Sebastian and Kuehl, Bailey and Langan, Michael and Lin, Daniel and Liu, Haokun and Lo, Kyle and Lochner, Jaron and MacMillan, Kelsey and Murray, Tyler and Newell, Chris and Rao, Smita and Rohatgi, Shaurya and Sayre, Paul and Shen, Zejiang and Singh, Amanpreet and Soldaini, Luca and Subramanian, Shivashankar and Tanaka, Amber and Wade, Alex D. and Wagner, Linda and Wang, Lucy Lu and Wilhelm, Chris and Wu, Caroline and Yang, Jiangjiang and Zamarron, Angele and Van Zuylen, Madeleine and Weld, Daniel S.},\\n  publisher = {arXiv},\\n  year = {2023},\\n  doi = {10.48550/ARXIV.2301.10140},\\n  url = {https://arxiv.org/abs/2301.10140},\\n}\\n'},\n {'name': 's2orc',\n  'description': 'Full-body paper text parsed from open-access PDFs. Identifies structural elements such as paragraphs, sections, and bibliography entries.\\n10M records in 30 4GB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"s2orc\" dataset contains parsed full-body text from selected papers.\\n\\nA subset of this data was previously released (in a different format) as S2ORC https://github.com/allenai/s2orc\\n\\nThe body text is parsed from PDF documents using Grobid, documented at https://grobid.readthedocs.io.\\nIts output is converted from XML into a single string with a set of annotation spans.\\n\\nSCHEMA\\n - externalIds: IDs of this paper in different catalogs\\n - content:\\n   - source:\\n\\t   - pdfUrls: URLs to the PDF\\n\\t   - oaInfo: license/url/status information from Unpaywall\\n   - text: Full body text as a single string\\n   - annotations: Annotated spans of the full body text\\n\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\n@inproceedings{lo-wang-2020-s2orc,\\n    title = \"{S}2{ORC}: The Semantic Scholar Open Research Corpus\",\\n    author = \"Lo, Kyle  and Wang, Lucy Lu  and Neumann, Mark  and Kinney, Rodney  and Weld, Daniel\",\\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\\n    month = jul,\\n    year = \"2020\",\\n    address = \"Online\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.447\",\\n    doi = \"10.18653/v1/2020.acl-main.447\",\\n    pages = \"4969--4983\"\\n}\\n'},\n {'name': 'tldrs',\n  'description': 'A short natural-language summary of the contents of a paper.\\n58M records in 30 200MB files.',\n  'README': 'Semantic Scholar Academic Graph Datasets\\n\\nThe \"tldrs\" dataset provides short natural-language summaries of a paper\\'s content.\\n\\nThe model is based on the SciTLDR model available at https://github.com/allenai/scitldr.\\n\\nLICENSE\\nThis collection is licensed under ODC-BY. (https://opendatacommons.org/licenses/by/1.0/)\\n\\nBy downloading this data you acknowledge that you have read and agreed to all the terms in this license.\\n\\nATTRIBUTION\\nWhen using this data in a product or service, or including data in a redistribution, please cite the following paper:\\n\\nBibTex format:\\n@article{cachola2020tldr,\\n  title={{TLDR}: Extreme Summarization of Scientific Documents},\\n  author={Isabel Cachola and Kyle Lo and Arman Cohan and Daniel S. Weld},\\n  journal={arXiv:2004.15011},\\n  year={2020},\\n}\\n\\n\\n'}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = datasets_response.json()['datasets']\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48ac4d7893340f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:10.382406571Z",
     "start_time": "2024-06-21T05:19:10.284275685Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for dataset in datasets:\n",
    "   # print(dataset['name'], dataset['description'])\n",
    "   with open(f\"{dataset['name']}.json\", \"w\") as jfile:\n",
    "       jfile.write(json.dumps(dataset, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce82c6da0dcd9fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:11.911129123Z",
     "start_time": "2024-06-21T05:19:10.383415156Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpapers\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 2\u001B[0m download_links_response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_url\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrelease_id\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/dataset/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/sessions.py:747\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    744\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 747\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/urllib3/response.py:1043\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1043\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1045\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m   1046\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/urllib3/response.py:935\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[0;32m--> 935\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    937\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[1;32m    939\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/urllib3/response.py:862\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    859\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 862\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    863\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m    864\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[1;32m    865\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    870\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    871\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/git/active/s2ag-corpus/venv/lib/python3.10/site-packages/urllib3/response.py:845\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    842\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1()\n\u001B[1;32m    843\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    844\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 845\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m/usr/lib/python3.10/http/client.py:466\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    465\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 466\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    469\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/usr/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/ssl.py:1303\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1300\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1301\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1302\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1303\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1305\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/usr/lib/python3.10/ssl.py:1159\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1159\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1161\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dataset_name = 'papers'\n",
    "download_links_response = requests.get(base_url + release_id + '/dataset/' + dataset_name, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca706fe5a759c54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:11.915928730Z",
     "start_time": "2024-06-21T05:19:11.912037459Z"
    }
   },
   "outputs": [],
   "source": [
    "download_links_response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1b0d3647c5bf7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-21T05:19:11.913793549Z"
    }
   },
   "outputs": [],
   "source": [
    "download_links = download_links_response.json()[\"files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2a3e43fee1ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:11.917096247Z",
     "start_time": "2024-06-21T05:19:11.915972571Z"
    }
   },
   "outputs": [],
   "source": [
    "download_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19951550280a8d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T05:19:11.917890848Z",
     "start_time": "2024-06-21T05:19:11.917726333Z"
    }
   },
   "outputs": [],
   "source": [
    "download_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c42633326f28d8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-21T05:19:11.932466233Z"
    }
   },
   "outputs": [],
   "source": [
    "for (i, link) in enumerate(download_links[3:]):\n",
    "    response = requests.get(link)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    with open(f\"/home/romilly/corpus202404/file{i+2}.gz\",\"wb\") as pf:\n",
    "        pf.write(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5f92193b4fe7f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-21T05:19:11.932740602Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
